# -*- coding: utf-8 -*-
"""Final Project HAM10000 - balanced - vgg16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W9xG-L-g3T_1vJd1czwVHRRD0-k65a-J

# Final Project HAM10000 - balanced - vgg16
"""

pip install wandb

import wandb

wandb.login()

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os
import shutil

import matplotlib.pyplot as plt
import numpy as np

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.utils.data as data
import torchvision
from torchvision import transforms, models, datasets
from torch.utils.data import Dataset, DataLoader
from torch.utils.data import DataLoader, random_split

import seaborn as sns
from PIL import Image
from glob import glob
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
from sklearn.utils import resample
from scipy import stats
from sklearn.utils import resample

"""# Defining the data"""

# Define directories
data_dir = "/content/drive/MyDrive/Data Scientist/final project/HAM10000/dataverse_files/HAM10000_images_part_1"

# Load the dataset
skin_df = pd.read_csv("/content/drive/MyDrive/Data Scientist/final project/HAM10000/dataverse_files/HAM10000_metadata")
skin_df.head()

# Print the count of images per diagnosis
print(skin_df['dx'].value_counts())

# Extract unique labels into a list
labels = skin_df['dx'].unique().tolist()
print(labels)

image_path = {
    os.path.splitext(os.path.basename(x))[0]: x
    for x in glob(os.path.join(data_dir, '**', '*.jpg'), recursive=True)
}

lesion_type_dict = {
    'nv': 'Melanocytic nevi',
    'mel': 'Melanoma',
    'bkl': 'Benign keratosis-like lesions ',
    'bcc': 'Basal cell carcinoma',
    'akiec': 'Actinic keratoses',
    'vasc': 'Vascular lesions',
    'df': 'Dermatofibroma'
}

# Create new columns
skin_df['image_path'] = skin_df['image_id'].map(image_path.get) # Map image paths to image_ids
skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get) # create cell type column from dx with full class names
skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes # Convert cell type to categorical

skin_df.head()

# Sample pics for each growth type

def load_image(image_path):
    return Image.open(image_path)

#Select Samples
unique_classes = skin_df['cell_type'].unique()
samples_per_class = 7

# Dictionary to hold selected samples
selected_samples = {class_: [] for class_ in unique_classes}

for class_ in unique_classes:
    # Filter samples by class and randomly select
    class_samples = skin_df[skin_df['cell_type'] == class_].sample(n=samples_per_class, random_state=42)
    for _, row in class_samples.iterrows():
        img = load_image(row['image_path'])  # Load the image
        selected_samples[class_].append(img)

# Visualize with class names
fig, axs = plt.subplots(len(unique_classes), samples_per_class, figsize=(20, 20))

for class_idx, class_ in enumerate(unique_classes):
    for img_idx, img in enumerate(selected_samples[class_]):
        ax = axs[class_idx, img_idx]
        ax.imshow(img)
        ax.axis('off')
        # Set title for the first image in each row to the class name
        if img_idx == 0:
            ax.set_ylabel(class_, rotation=0, size='large', labelpad=60, verticalalignment='center')
        # Optionally, add class names to each image
        ax.set_title(class_, fontsize=10)

plt.tight_layout()
plt.show()

"""# EDA"""

skin_df.info()

skin_df.isnull().sum()

"""there are 57 null samples in age so they need to be filled. The mean of the total age will be used to fill the na"""

skin_df['age'].fillna((skin_df['age'].mean()), inplace=True)
skin_df.isnull().sum()

skin_df.info()

"""now we see that there are no null in the dataframe"""

# using graphs we can check the distribution of the growth
sns.set_style("whitegrid")

# Initialize the figure with a size
plt.figure(figsize=(12, 8))

# Plot for Cell Type
plt.subplot(221)  # 2x2 grid, first subplot
skin_df['cell_type'].value_counts().plot(kind='bar', color='skyblue')
plt.ylabel('Count')
plt.title('Cell Type')

# Plot for Sex distribution
plt.subplot(222)  # 2x2 grid, second subplot
skin_df['sex'].value_counts().plot(kind='bar', color='lightgreen')
plt.ylabel('Count')
plt.title('Sex')

# Plot for Localization distribution
plt.subplot(223)  # 2x2 grid, third subplot
skin_df['localization'].value_counts().plot(kind='bar', color='lightcoral')
plt.ylabel('Count')
plt.title('Localization')

# Plot for Age distribution
plt.subplot(224)  # 2x2 grid, fourth subplot
# Filter out null ages, no need for a separate variable
sns.histplot(skin_df[skin_df['age'].notnull()]['age'], kde=True, color='red')
plt.title('Age')

# Automatically adjust subplot params for a neat layout
plt.tight_layout()

# Display the plots
plt.show()

print(skin_df['cell_type'].value_counts())

print(skin_df['localization'].value_counts())

"""There appears to be a very different distribution of the number of lessions so there will be a need to deal with it"""

#creating vtrain and test split
y = skin_df['cell_type_idx']
X = skin_df.drop('cell_type_idx', axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.head()

# Combine train image and label dataframe as one dataframe to have a complete dataframe to work on
X_train.insert(0, 'cell_type_idx', value=y_train.values)
train_df = X_train
X_test.insert(0, 'cell_type_idx', value=y_test.values)
test_df = X_test

test_df.head()

test_df.info()

"""# Normalizing the train dataset"""

train_df.info()

# max class
print("Class distribution after balancing:\n", train_df['cell_type_idx'].value_counts())

#Creating copies to balance the  train data
max_class_size = 5367
df_list = []

for class_index, group in train_df.groupby('cell_type_idx'):
    df_class_balanced = resample(group,
                                 replace=True,     # Sample with replacement
                                 n_samples=max_class_size,    # Match number in majority class
                                 random_state=123) # Reproducible results
    df_list.append(df_class_balanced)

# Combine all oversampled classes back into one DataFrame
train_df_balanced = pd.concat(df_list)

train_df_balanced = train_df_balanced.sample(frac=1, random_state=123).reset_index(drop=True)

test_df = test_df.sample(frac=1, random_state=123).reset_index(drop=True)

# Verify the balancing
print("Class distribution after balancing:\n", train_df_balanced['cell_type_idx'].value_counts())

# Set the style of seaborn for more appealing plots
sns.set_style("whitegrid")

# Initialize the figure with a size
plt.figure(figsize=(12, 8))

# Plot for Cell Type
plt.subplot(221)  # 2x2 grid, first subplot
train_df_balanced['cell_type'].value_counts().plot(kind='bar', color='skyblue')
plt.ylabel('Count')
plt.title('Cell Type')

# Plot for Sex distribution
plt.subplot(222)  # 2x2 grid, second subplot
train_df_balanced['sex'].value_counts().plot(kind='bar', color='lightgreen')
plt.ylabel('Count')
plt.title('Sex')

# Plot for Localization distribution
plt.subplot(223)  # 2x2 grid, third subplot
train_df_balanced['localization'].value_counts().plot(kind='bar', color='lightcoral')
plt.ylabel('Count')
plt.title('Localization')

# Plot for Age distribution
plt.subplot(224)  # 2x2 grid, fourth subplot
# Filter out null ages, no need for a separate variable
sns.histplot(skin_df[skin_df['age'].notnull()]['age'], kde=True, color='red')
plt.title('Age')

# Automatically adjust subplot params for a neat layout
plt.tight_layout()

# Display the plots
plt.show()

class CustomImageDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        """
        Initialize the dataset.

        Parameters:
            dataframe (pd.DataFrame): DataFrame containing image paths and labels.
            transform (callable, optional): Optional transform to be applied on a sample.
        """
        self.dataframe = dataframe
        self.transform = transform

    def __len__(self):
        """
        Return the number of items in the dataset.
        """
        return len(self.dataframe)

    def __getitem__(self, idx):
        """
        Fetch the item (image and label) at the specified index.

        Parameters:
            idx (int): Index of the item to be fetched.

        Returns:
            tuple: (image, label) where image is the transformed image and label is the class label.
        """
        # Use the full path directly from the DataFrame
        img_path = self.dataframe.iloc[idx]['image_path']  # Adjust column name as necessary
        image = Image.open(img_path).convert('RGB')
        label = torch.tensor(int(self.dataframe['cell_type_idx'][idx]))

        if self.transform:
            image = self.transform(image)

        return image, label

"""# Model Preparation"""

# Hyperparameters & settings
num_classes = 7  # Adjust to your dataset
batch_size = 32
num_epochs = 20  # You can adjust the number of epochs
learning_rate = 0.001

#data augmentation
train_transform = transforms.Compose([transforms.Resize((224, 224)),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.RandomVerticalFlip(),
                                     transforms.RandomRotation(20),
                                     transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),
                                     transforms.ToTensor(),
                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
test_transform = transforms.Compose([transforms.Resize((224, 224)),
                                   transforms.ToTensor(),
                                   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])

# Create the dataset
train_data_torch = CustomImageDataset(train_df_balanced, transform=train_transform)
test_data_torch = CustomImageDataset(test_df, transform=test_transform)

# Create dataloaders
train_loader = DataLoader(train_data_torch, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_data_torch, batch_size=batch_size)

wandb.init(project='Final Project HAM10000 - balanced - vgg16')
wandb.config = {
  "learning_rate": learning_rate,
  "epochs": num_epochs,
  "batch_size": train_loader.batch_size
}

# Load the pre-trained vgg16 model
model = models.vgg16(pretrained=True)

# Check if CUDA is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Modify the last layer
model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)

# Then move the model to the GPU
model = model.to(device)

# Define Loss Function and Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)

"""# Model training"""

model.train()  # Set the model to training mode
for epoch in range(num_epochs):
    running_loss = 0.0
    for inputs, labels in train_loader:
        # Move data to the appropriate device
        inputs = inputs.to(device)
        labels = labels.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # Backward and optimize
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)
    epoch_loss = running_loss / len(train_loader.dataset)

    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')

    # Log the metrics to wandb
    wandb.log({"epoch": epoch+1, "loss": epoch_loss})

"""# Evaluate the Model"""

model.eval()  # Set the model to evaluation mode

total_loss = 0.0
correct_predictions = 0
total_predictions = 0

# Criterion for calculating loss
criterion = torch.nn.CrossEntropyLoss()

# No gradient calculations
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
        total_loss += loss.item() * images.size(0)

        _, predicted = torch.max(outputs, 1)
        correct_predictions += (predicted == labels).sum().item()
        total_predictions += labels.size(0)

# Calculate average loss and accuracy
avg_loss = total_loss / total_predictions
accuracy = correct_predictions / total_predictions * 100

# Log validation loss and accuracy to wandb
wandb.log({"val_loss": avg_loss, "val_accuracy": accuracy})

# Presenting the results
print(f'Validation Loss: {avg_loss:.4f}')
print(f'Validation Accuracy: {accuracy:.2f}%')

# Ensure the model is in evaluation mode
model.eval()

# Initialize lists to store true and predicted labels
true_labels = []
pred_labels = []

# Disable gradient calculation for inference
with torch.no_grad():
    for images, labels in test_loader:

        # Move images to the device
        images, labels = images.to(device), labels.to(device)

        # Forward pass
        outputs = model(images)

        # Get the prediction class with the highest score
        _, predicted = torch.max(outputs, 1)

        # Append true and predicted labels for this batch
        # Move tensors to CPU before converting to NumPy
        true_labels.extend(labels.cpu().numpy())
        pred_labels.extend(predicted.cpu().numpy())

# Calculate the confusion matrix
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(true_labels, pred_labels)

# Plot the confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

wandb.finish()

# Define the directory path where you want to save the file
dir_path = '/content/drive/My Drive'


# Define the full path to the file
filename = 'balanced_vgg16_pickle.pkl'
file_path = os.path.join(dir_path, filename)

with open(file_path, 'wb') as file:
    pickle.dump(model, file)

print(f'Model saved to {file_path}')

from google.colab import drive
drive.mount('/content/drive')

filename = 'balanced_vgg16_model.pth'
model_path = '/content/drive/My Drive/' + filename  # Save to Google Drive

torch.save(model.state_dict(), model_path)
print(f'Model saved to {model_path}')

# saving Model with pickle

import pickle

# Saving the model to a file
filename = 'balanced_vgg16_pickle.pkl'
with open(filename, 'wb') as file:
    pickle.dump(model, file)

print(f'Model saved to {filename}')

# Saving a PyTorch Model - Saving the entire model
filename = 'balancad_vgg16_pytorch.pth'
torch.save(model, filename)

print(f'Entire model saved to {filename}')



